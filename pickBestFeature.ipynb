{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96ade92f",
   "metadata": {},
   "source": [
    "### 特征选择\n",
    "\n",
    "特征选择的标准：信息增益(information gain)，即划分数据集之后信息发生的变化。计算每个特征值划分数据集获得的信息增益，获得信息增益最高的特征就是最好的选择。\n",
    "\n",
    "香农熵(shannon)或者简称为熵(entropy)：信息的期望值。在信息论与概率统计中，熵是表示随机变量不确定性的度量。熵越大，随机变量的不确定性就越大。\n",
    "\n",
    "假设$p(x_i)$是选择该分类的概率(从图中看出概率越小，熵越大)，则该类别$x_i$的信息定义为\n",
    "$$l(x_i) = -\\log_2 p(x_i)$$\n",
    "\n",
    "假设待分类的事物划分在多个分类，即标签类别，且分类数目为$K$，则可计算所有类别所有可能值包含的信息期望值(数学期望)为\n",
    "$$H = -\\sum_{i=1}^n p(x_i) \\log_2 p(x_i)$$\n",
    "\n",
    "经验熵(empirical entropy)：熵中的概率由数据估计(特别是最大似然估计)得到时所对应的熵，浅显的解释就是，这概率是我们根据数据数出来的。\n",
    "假设训练数据集的经验熵为$H(D)$，$|D|$表示其样本容量，设有$K$个类，$\\{C_k\\}_{k=1}^K$，$|C_k|$为属于类$C_k$的样本个数，则经验熵公式为\n",
    "$$H(D) = -\\sum_{k=1}^K \\frac{|C_k|}{|D|} \\log_2 \\frac{|C_k|}{|D|}$$\n",
    "\n",
    "总结；经验熵是针对于某个数据集的，不涉及到特征选择和划分数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31af0fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "def l(p):\n",
    "    return -np.log2(p)\n",
    "p = np.linspace(1e-3, 1, 100, endpoint=True)\n",
    "fig = plt.figure()  \n",
    "ax = fig.add_subplot(221)  \n",
    "ax.plot(p, l(p))\n",
    "ax.set_xlabel('probability')\n",
    "ax.set_ylabel('entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bf914d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 'no'], [0, 0, 0, 1, 'no'], [0, 1, 0, 1, 'yes'], [0, 1, 1, 0, 'yes'], [0, 0, 0, 0, 'no'], [1, 0, 0, 0, 'no'], [1, 0, 0, 1, 'no'], [1, 1, 1, 1, 'yes'], [1, 0, 1, 2, 'yes'], [1, 0, 1, 2, 'yes'], [2, 0, 1, 2, 'yes'], [2, 0, 1, 1, 'yes'], [2, 1, 0, 1, 'yes'], [2, 1, 0, 2, 'yes'], [2, 0, 0, 0, 'no']]\n",
      "0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "def createDataSet():\n",
    "    dataSet = [[0, 0, 0, 0, 'no'],\n",
    "            [0, 0, 0, 1, 'no'],\n",
    "            [0, 1, 0, 1, 'yes'],\n",
    "            [0, 1, 1, 0, 'yes'],\n",
    "            [0, 0, 0, 0, 'no'],\n",
    "            [1, 0, 0, 0, 'no'],\n",
    "            [1, 0, 0, 1, 'no'],\n",
    "            [1, 1, 1, 1, 'yes'],\n",
    "            [1, 0, 1, 2, 'yes'],\n",
    "            [1, 0, 1, 2, 'yes'],\n",
    "            [2, 0, 1, 2, 'yes'],\n",
    "            [2, 0, 1, 1, 'yes'],\n",
    "            [2, 1, 0, 1, 'yes'],\n",
    "            [2, 1, 0, 2, 'yes'],\n",
    "            [2, 0, 0, 0, 'no']]\n",
    "    labels = ['不放贷', '放贷']\n",
    "    return dataSet, labels\n",
    "\n",
    "def compute_empEntropy(dataSet):\n",
    "    numrows = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for row in dataSet:\n",
    "        curlabel = row[-1]\n",
    "        if curlabel not in labelCounts:\n",
    "            labelCounts[curlabel] = 0\n",
    "        labelCounts[curlabel] += 1\n",
    "    entropy = 0\n",
    "    for key in labelCounts:\n",
    "        prob = labelCounts[key] / numrows\n",
    "        entropy -= prob * log(prob, 2)\n",
    "    return entropy\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataSet, labels = createDataSet()\n",
    "    print (dataSet)\n",
    "    print (compute_empEntropy(dataSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44a4e2",
   "metadata": {},
   "source": [
    "条件熵(conditional entropy) $H(Y|X)$：随机变量X给定的条件下, $Y$的条件概率分布的熵对$X$的数学期望，\n",
    "$$H(T|X) = \\sum_{i=1}^n p_i H(Y|X=x_i), \\quad p_i = P(X = x_i), \\quad i = 1, \\dots, n$$\n",
    "\n",
    "条件经验熵(empirical conditional entropy)：条件熵中的概率由数据估计(特别是极大似然估计)得到时，所对应的条件熵\n",
    "\n",
    "特征$A$对训练数据集$D$的信息增益：集合$D$的经验熵$H(D)$与特征$A$给定条件下$D$的经验条件熵$H(D|A)$之差，即互信息(mutual information)。决策树学习中的信息增益等价于训练数据集中类与特征的互信息。\n",
    "$$g(D) = H(D) - H(D|A)$$\n",
    "\n",
    "假设特征$A$有$n$个不同的取值$\\{a_1, a_2, \\dots, a_n\\}$，根据特征$A$的取值将$D$划分为$n$个子集$\\{D_1, D_2, \\dots, D_n\\}$，$|D_i|$为$D_i$的样本个数。记子集$D_i$中属于$C_k$的样本的集合为$D_{ik}$，即$D_{ik} = D_i \\cap C_k$，$|D_{ik}|$为$D_{ik}$的样本个数。于是经验条件熵的公式可以些为\n",
    "$$H(D|A) = \\sum_{i=1}^n \\frac{|D_i|}{|D|} H(D_i) = -\\sum_{i=1}^n \\frac{|D_i|}{|D|} \\sum_{k=1}^K \\frac{|D_{ik}|}{|D_i|} \\log_2{\\frac{|D_{ik}|}{|D_i|}}$$\n",
    "\n",
    "总结：给定特征$A$，有$n$个取值，每个取值对应一个数据子集$D_i$，该子集的熵$H(D_i)$可通过子集$D_i$内的$K$个标签分类计算。所有子集的熵的期望即为训练数据集$D$在特征$A$下的条件熵。$D$的熵$H(D)$，减去$D$在$A$下的条件熵$H(D|A)$，即互信息，为特征$A$对训练数据集$D$的信息增益$g(D, A)$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a8eb3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个特征的增益为0.083\n",
      "第1个特征的增益为0.324\n",
      "第2个特征的增益为0.420\n",
      "第3个特征的增益为0.363\n",
      "最优特征索引值:2\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "def compute_empEntropy(dataSet):\n",
    "    numrows = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for row in dataSet:\n",
    "        curlabel = row[-1]\n",
    "        if curlabel not in labelCounts:\n",
    "            labelCounts[curlabel] = 0\n",
    "        labelCounts[curlabel] += 1\n",
    "    entropy = 0\n",
    "    for key in labelCounts:\n",
    "        prob = labelCounts[key] / numrows\n",
    "        entropy -= prob * log(prob, 2)\n",
    "    return entropy\n",
    "\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    axis: index of feature, ranging from 0 to 3 since there are 4 features in our dataSet\n",
    "    values: values of the selected feature, e.g., 1st feature: 0->青年; 1->中年; 2->老年\n",
    "    Returns:\n",
    "    subDateSet of given value of axis, subtracting [axis] feature\n",
    "    \"\"\"\n",
    "    returnDateSet = []\n",
    "    for featureVec in dataSet:\n",
    "        if featureVec[axis] == value:\n",
    "            reducedFeatureVec = featureVec[:axis]\n",
    "            reducedFeatureVec.extend(featureVec[axis+1:])\n",
    "            returnDateSet.append(reducedFeatureVec)\n",
    "    return returnDateSet\n",
    "\n",
    "def pick_feature(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    baseEntropy = compute_empEntropy(dataSet)\n",
    "    bestInfoGain = 0.\n",
    "    for i in range(numFeatures):\n",
    "        featureList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featureList)\n",
    "        newEntropy = 0.\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet) / len(dataSet)\n",
    "            newEntropy += prob * compute_empEntropy(subDataSet)\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        print(\"第%d个特征的增益为%.3f\" % (i, infoGain))\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataSet, features = createDataSet()\n",
    "    print(\"最优特征索引值:\" + str(pick_feature(dataSet)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
